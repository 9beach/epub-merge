#!/bin/bash

set -euo pipefail

readonly DEBUG=${DEBUG:-}

epub_version=""
opf_files=()
ncx_files=()
nav_files=()
readonly merged_ncx_id="ncx"
readonly merged_ncx="toc.ncx"
first_ncx_id=""
first_ncx=""
readonly merged_nav_id="nav"
readonly merged_nav="nav.xhtml"
first_nav_id=""
first_nav=""

# --- From args

epub_files=() 
output_dir="$(realpath "$(pwd)")"
overwrite_existing=""
toc_volume_prefix=""
toc_volume_suffix=""
toc_volume_given=""
filename_label_given=""
toc_volume_labels=()
epub_name="" 
epub_title=""
epub_lang=""
do_not_sort_params=""
extract_mode=""
quiet_mode=""

temp_dir=""
temp_file=""
temp_epub=""
xml_formatter=""
iconv_has_utf_8_mac="$(iconv -l | grep "UTF-8-MAC" || true)"
readonly iconv_has_utf_8_mac
readonly sp="[[:space:]]"
readonly uuid_pattern='[0-9a-fA-F]\{8\}-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{4\}'\
'-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{12\}'

# --- Utility functions

show_usage() {
	cat >&2 << 'EOF'
epub-merge -- merge multiple ePUB files into one or extract merged ePUB

Usage:
  epub-merge [-fOqV] [-d directory] [-l lang] [-p prefix] [-s suffix]
             [-t title] [-v labels] file ...
  epub-merge -x file

Options:
  -d directory   Set output directory (default: current directory).
  -f             Force overwrite of existing files.
  -l lang        Set language code (e.g., ko, en, ja, zh, ru).
  -O             Disable natural sorting of input files.
  -p prefix      Add prefix to table of contents volume labels.
  -q             Quiet mode, suppress progress messages.
  -s suffix      Add suffix to table of contents volume labels.
  -t title       Set custom title and output filename.
  -v labels      Set custom volume labels (e.g., "Love//Peace//Hate").
  -V             Get custom volume labels from filenames.
  -x             Extract merged ePUB into original files.
  -h             Show this help message.

Notes:
  - At least one input file is required for merging.
  - Use -x for extraction mode with a single ePUB file.
EOF
}

cleanup() {
	# Cleanup temp files on exit
	if [[ -f "${temp_epub}" ]]; then
		rm -f "$temp_epub"
	fi
	if [[ -f "${temp_file}" ]]; then
		rm -f "$temp_epub"
	fi
	if [[ -d "${temp_dir}" ]]; then
		rm -rf "$temp_dir"
	fi
}

if [[ "$OSTYPE" == "darwin"* ]]; then
	sed_i() {
		sed -i '' "$@"
	}
else
	sed_i() {
		sed -i "$@"
	}
fi

log() {
	if [[ -z "$quiet_mode" ]]; then
		printf '\033[90m%s\033[0m\n' "$*" >&2
	fi
}

orange_log() {
	if [[ -z "$quiet_mode" ]]; then
		printf '\033[38;5;208m%s\033[0m\n' "$*" >&2
	fi
}

debug() {
	# Print blue debug messages when DEBUG is enabled.
	if [[ -n "$DEBUG" ]]; then
		printf "\033[34m[DEBUG] #${BASH_LINENO[1]} %s\033[0m\n" "$*" >&2
	fi
}

debug_var() {
	# Print blue debug messages of a variable when DEBUG is enabled.
	# e.g., debug_var variable_name_without_dollar_prefix
	debug "$1=\"${!1}\""
}

debug_func() {
	# ${FUNCNAME[2]} / ${FUNCNAME[1]} → caller function / current function
	if [ "${1:-}" != "$*" ]; then
		local joined
		joined=$(IFS=,; echo "$*")
		debug "function: ${FUNCNAME[2]} / ${FUNCNAME[1]} ($joined)"
	else
		debug "function: ${FUNCNAME[2]} / ${FUNCNAME[1]}"
	fi
}

error() {
	# Print red error message and exit.
	printf "\033[31mError (epub-merge): %s\033[0m\n" "$*" >&2
	exit 1
}

normalize_path() {
	# './aa/./x/y/../../z' -> 'aa/z'
	sed -E '
	s#"\./#"#
	s#/\./#/#
	:a
	s#/[^/]+/\.\./#/#g
	ta' ${1:+"$1"}
}

# --- XML utility functions

readonly xml_formatter_warning='The XML formatter is not installed, which "\
"may cause errors during the merge process. Please install xmllint.'

if command -v xmllint &> /dev/null; then
	xml_formatter="xmllint"
elif command -v python3 &> /dev/null; then
	xml_formatter="python3"
else
	xml_formatter="cat"
	log "$xml_formatter_warning"
fi

readonly python3_xml_formatter="import xml.dom.minidom as x,sys; "\
"print(x.parseString(sys.stdin.read() if len(sys.argv)==1 "\
"else open(sys.argv[1]).read()).toprettyxml(indent='  '))"

if [[ "$xml_formatter" == "xmllint" ]]; then
	format_xml() {
		xmllint --recover --format --noblanks "${1:--}" 2> /dev/null
	}
elif [[ "$xml_formatter" == "python3" ]]; then
	format_xml() {
		python3 -c "$python3_xml_formatter" ${1:+"$1"} 2> /dev/null \
			| grep -v "^ *$"
	}
else
	format_xml() {
		cat ${1:+"$1"}
	}
fi

split_xml() {
	# Split XML elements for easier processing
	tr -d '\n' < "${1:-/dev/stdin}" | sed 's/</\n</g'
}

get_xml_attr() {
	# Extract attribute value from XML pattern
	debug_func "$@"
	local pattern="$1" attr="$2"

	sed -nE "\|${pattern}| {
		s|.*${attr}=[\"']([^\"']*)[\"'].*|\1|p;
		q
	}" ${3:+"$3"}
}

escape_xml() {
	# Escape special XML characters and control chars.
	printf '%s' ${1:+"$1"} | sed \
		-e 's/&/\&amp;/g' \
		-e 's/</\&lt;/g' \
		-e 's/>/\&gt;/g' \
		-e 's/"/\&quot;/g' \
		-e "s/'/\&apos;/g"
}

escape_xml_for_sed() {
	# Escape special XML characters and control chars.
	# Safe for `sed` replacement strings
	printf '%s' "${1-}" | sed \
		-e 's/\\/\\\\/g' \
		-e 's/&/\\\&amp;/g' \
		-e 's/</\\\&lt;/g' \
		-e 's/>/\\\&gt;/g' \
		-e 's/"/\\\&quot;/g' \
		-e "s/'/\\\&apos;/g" \
		-e 's/\//\\\//g'
}

get_xml_element() {
	# Extract XML element by pattern
	debug_func "$@"
	local pattern="$1"

	sed -nE "
		/<[^>]*${pattern}[^>]*>/ {
			s#.*(<[^>]*${pattern}[^>]*>)#\1#p;
			q
		}" ${2:+"$2"}
}

extract_and_modify_xml() {
	# Extract content between XML tags and modify paths/IDs
	debug_func "$@"
	local tag="$1" pattern="$2" dir="$3" suffix="$4"
	if [[ "$dir" == "0" ]]; then
		local remove_cover=''
	else
		local remove_cover='s/properties=.cover-image.//g'
	fi

	sed -E "
	/<${tag}[^>]*${pattern}[^>]*>/,/<\/${tag}/!d
	/<\/?${tag}/d
	/^$/d
	s:(src|href)=\":&$dir/:g
	s:(id|idref)=\"[^\"]*:&-${suffix}:g
	$remove_cover
	" ${5:+"$5"}
}

xml_grep_before_tag() {
	# Extract content before specified tag
	debug_func "$@"
	local tag_name="$1"

	sed -E "/<\/*${tag_name}[^>]*>/,\$d" ${2:+"$2"}
}

modify_opf_metadata() {
	# Replace title and append suffix('-0') to cover ID
	debug_func "$@"
	local epub_title="$1"
	sed -E "
	s|(<dc:title[^>]*>).*</dc:title>|\1$epub_title</dc:title>|
	/name=\"cover\"/s|content=\"[^\"]*|&-0|
	" \
	| grep -viE 'calibre:(series|title_sort)'
}

awk_filter_dups=$(cat <<'EOF'
/<manifest/ { in_manifest = 1 }
/<\/manifest/ { in_manifest = 0; print; next }

in_manifest && /<item[^>]*href=/ {
	if (match($0, /href=["']([^"']*)["']/)) {
		href = substr($0, RSTART + 6, RLENGTH - 7)
		if (href != "") {
			href_lower = tolower(href)

			if (href_lower ~ /\.(ttf|otf|woff|woff2|eot)(\?|$)/) {
				if (seen[href_lower]) {
					next
				}
				seen[href_lower] = 1
			}
		}
	}
}
{ print }
EOF
)
readonly awk_filter_dups

filter_dups() {
	# Remove duplicate manifest font items from stdin (keep first 
	# occurrence only)
	awk "$awk_filter_dups"
}

# --- ePUB utility functions

get_version() {
	# Get ePUB version from file
	local epub="$1" opf_path
	opf_path="$(unzip -p "$epub" META-INF/container.xml \
		| get_xml_attr full-path full-path)"

	[ -z "$opf_path" ] && return 1

	unzip -p "$epub" "$opf_path" \
		| split_xml \
		| get_xml_attr 'package.*version' version
}

check_deps() {
	# Check system dependencies
	local missing_deps=()

	for cmd in unzip zip uuidgen; do
		if ! command -v "$cmd" > /dev/null 2>&1; then
			missing_deps+=("$cmd")
		fi
	done

	if [[ ${#missing_deps[@]} -gt 0 ]]; then
		log "Missing required commands '${missing_deps[*]}'"
		return 1
	fi
}

get_prefix() {
	# Extract common prefix from filenames
	local file1="$1" file2="$2" common="" base1 base2 min_length

	base1="$(basename "$file1")"
	base2="$(basename "$file2")"
	min_length=$((${#base1} < ${#base2} ? ${#base1} : ${#base2}))

	for ((i=0; i<min_length; i++)); do
		if [[ "${base1:i:1}" == "${base2:i:1}" ]]; then
			common+="${base1:i:1}"
		else
			break
		fi
	done

	# Remove trailing numbers, brackets, and separators
	echo "$common" | sed -e 's/[-_[( ]*$//' -e 's/ [0-9][0-9]*$//'
}

to_nfc() {
	# Convert to NFC encoding
	if [ -n "$iconv_has_utf_8_mac" ]; then
		iconv -f UTF-8-MAC -t UTF-8 ${1:+"$1"}
	else
		cat ${1:+"$1"}
	fi
}

# --- ePUB validation and processing functions

validate_epub() {
	# Validate ePUB structure
	local epub_file="$1" is_merged="${2:-}"
	temp_file="$(mktemp)"

	if ! unzip -Z1 "$epub_file" > "$temp_file"; then
		log "Invalid ZIP file '$epub_file'"
		return 1
	fi

	if ! grep -qEi "(^mimetype|^META-INF/container.xml|\.opf)$" \
			"$temp_file"; then
		log "Missing required file '$pattern' in '$epub_file'"
		return 1
	fi

	if [[ "$is_merged" == 1 ]]; then
		local merged_opf_count opf_backup_count
		merged_opf_count="$(grep -c "^content.opf" "$temp_file"|| true)"
		opf_backup_count="$(grep -cE "^\.epub-merge/[0-9]+.opf$" \
			"$temp_file" || true)"

		if [[ "$merged_opf_count" -ne 1 \
			|| "$opf_backup_count" -lt 2 \
		]]; then
			log "'$epub_file' is not a valid merged ePUB"
			return 1
		fi
	fi
}

fix_playorder() {
	# Fix NCX playOrder attributes
	local mark_done="_zxi%dt"
	# Re-sequence playOrder attributes for proper navigation
	awk -v regex="playOrder=\"[0-9][0-9]*\"" -v prefix="${mark_done}=\"" \
		-v suffix="\"" '
	{
		while (match($0, regex)) {
			$0 = substr($0, 1, RSTART-1) \
				prefix (++count) \
				suffix \
				substr($0, RSTART+RLENGTH)
			}
		print $0;
	}' \
	| sed "s/${mark_done}/playOrder/g"
}

gen_opf_header() {
	# Generate OPF header section
	local opf_file="$1" epub_title="$2"

	xml_grep_before_tag manifest "$opf_file" \
		| modify_opf_metadata "$epub_title"
}

sed_fix_font_paths=$(cat <<'EOF'
s#href=["'].*/[^"']*/([^/]+\.(ttf|otf|woff|woff2|eot))["']#href="fonts/\1"#gi
EOF
)
readonly sed_fix_font_paths

fix_font_paths() {
	# Fix font paths for merged ePUB
	# ='path/to/myfont.TTF' -> ='fonts/myfont.TTF'
	sed -E "$sed_fix_font_paths"
}

# --- Command line parsing and validation

parse_args() {
	while getopts "n:t:l:p:v:s:d:fOqVx" opt; do
		case "$opt" in
			f) overwrite_existing=1 ;;
			d) output_dir="$(realpath "$OPTARG")" ;;
			n) epub_name="$OPTARG" ;;
			v) label_lines=$(echo -E "$OPTARG" \
				| sed -E "s#$sp*//$sp*#\n#g")
			   while IFS= read -r l; do
				l="${l#"${l%%[![:space:]]*}"}"
				l="${l%"${l##*[![:space:]]}"}"
				toc_volume_labels+=("$l")
			   done <<< "$label_lines" ;;
			V) filename_label_given=1 ;;
			t) epub_title="$OPTARG" ;;
			l) epub_lang="$OPTARG" ;;
			p) toc_volume_prefix="$OPTARG"
			   toc_volume_given=1 ;;
			s) toc_volume_suffix="$OPTARG"
			   toc_volume_given=1 ;;
			O) do_not_sort_params=1 ;;
			q) quiet_mode=1 ;;
			x) extract_mode=1 ;;
			\?) show_usage; exit 1 ;;
		esac
	done

	readonly overwrite_existing output_dir extract_mode \
		toc_volume_given do_not_sort_params quiet_mode 
}

validate_args() {
	if [[ -n "$extract_mode" ]]; then
		if [[ $# -ne 1 ]]; then
			show_usage
			exit 1
		fi
	elif [[ $# -lt 2 ]]; then
		show_usage
		exit 1
	fi

	for file in "$@"; do
		[[ -f "$file" ]] || error "File not found '$file'"
	done

	if [[ ${#toc_volume_labels[@]} -ne 0 \
			&& "$filename_label_given" -eq 1 ]]; then
		error "The -V and -v options cannot be used together"
	fi
}

gen_output_names() {
	# Generate output filename and title from input files
	epub_name="${epub_title:-$epub_name}"

	if [[ -z "$epub_name" ]]; then
		epub_name="$(get_prefix "$(basename "$1")" "$(basename "$2")")"
	fi

	if [[ -z "$epub_name" ]]; then
		error "Cannot determine output name from '$1' and '$2'"
	fi

	epub_title="${epub_title:-$epub_name}"
	epub_name="${epub_name//[\/:*?<>|\"\\]/_}"  # safe filename
	epub_title="$(escape_xml_for_sed "$epub_title")"

	if [[ $overwrite_existing != 1 && -f "$epub_name.epub" ]]; then
		error "$epub_name.epub: already exists"
	fi
}

sort_files() {
	# Sort input files naturally unless disabled
	if [[ -n "${do_not_sort_params:-}" ]]; then
		epub_files=("$@")
	else
		local sorted_files=()
		while IFS= read -r -d '' file; do
			sorted_files+=("$file")
		done < <(printf "%s\0" "$@" | sort -zV)
		epub_files=("${sorted_files[@]}")
	fi
}

extract_files() {
	# Extract all ePUB files to numbered directories
	for i in "${!epub_files[@]}"; do
		log "Extracting ${epub_files[i]}"
		mkdir -p "$temp_dir/$i"
		unzip -q "${epub_files[i]}" -d "$temp_dir/$i" \
			|| error "Failed to extract '${epub_files[i]}'"
	done
}

detect_lang() {
	# Detect language from OPF content
	local opf_file="$1" lang="$2" lang_from_opf char

	if [[ -n "$lang" ]]; then
		echo "$lang"
		return
	fi

	# Extract language from metadata first
	lang_from_opf=$(grep -ho -E -m1 '<dc:language>.*</dc:language>' \
			"$opf_file" 2> /dev/null \
		| sed 's/<[^>]*>//g')

	if [[ -n "$lang_from_opf" ]]; then
		echo "$lang_from_opf"
		return
	fi

	debug "auto-detect language"

	# Detect language by character patterns in a single grep call
	char=$(grep -Eom1 '[가-힣]|[ぁ-ゟァ-ヿ]|[一-龯]|[А-Яа-яЁё]' \
		"$opf_file" 2> /dev/null)
	case "$char" in
		[가-힣]*) echo "ko" ;;
		[ぁ-ゟァ-ヿ]*) echo "ja" ;;
		[一-龯]*) echo "zh" ;;
		[А-Яа-яЁё]*) echo "ru" ;;
		*) echo "en" ;;
	esac
}

collect_file_paths_and_format_xml() {
	# Collect OPF/NCX/NAV file paths, and format XML
	for i in "${!epub_files[@]}"; do
		local cur_epub="${epub_files[i]}"

		# Get OPF path
		local cur_opf opf_dir cur_ncx cur_nav
		cur_opf="$(get_xml_attr full-path full-path \
			"$i/META-INF/container.xml")"
		opf_dir="$(dirname "$cur_opf")"

		[[ -n "$cur_opf" || ! -f "$i/$cur_opf" ]] \
			|| error "Can't find OPF in container.xml of $cur_epub"

		cur_opf="$i/$cur_opf"
		cur_ncx="$(get_xml_attr "x-dtbncx" "href" "$cur_opf")"
		opf_files[i]="$cur_opf"

		format_xml "$cur_opf" > .x && mv .x "$cur_opf"

		# Get NCX
		if [[ -f "$i/$opf_dir/$cur_ncx" ]]; then
			format_xml "$i/$opf_dir/$cur_ncx" > .x \
				&& mv .x "$i/$opf_dir/$cur_ncx"

		else
			cur_ncx=""
		fi

		if [[ -z "$first_ncx_id" && -n "$cur_ncx" ]]; then
			first_ncx_id="$(get_xml_attr \
				"$cur_ncx" "id" "$cur_opf")"
			first_ncx="$i/$opf_dir/$cur_ncx"
		fi

		ncx_files[i]="${cur_ncx:+$i/$opf_dir/$cur_ncx}"

		[[ $epub_version == "2.0" ]] && continue

		# Get NAV (ePUB 3.0 only)
		cur_nav="$(get_xml_attr \
			"properties=.nav." "href" "$cur_opf")"

		if [[ ! -f "$i/$opf_dir/$cur_nav" ]]; then
			cur_nav=""
		else
			format_xml "$i/$opf_dir/$cur_nav" > .x \
				&& mv .x "$i/$opf_dir/$cur_nav"
		fi

		if [[ -z "$first_nav_id" && -n "$cur_nav" ]]; then
			first_nav_id="$(get_xml_attr \
				"$cur_nav" "id" "$cur_opf")"
			first_nav="$i/$opf_dir/$cur_nav"
		fi

		nav_files[i]="${cur_nav:+$i/$opf_dir/$cur_nav}"
	done
}

get_valume_labels() {
	# Detect volume labels based on language
	local prefix="$toc_volume_prefix"
	local suffix="$toc_volume_suffix"

	if [[ -n "$toc_volume_given" ]]; then
		return
	fi

	# Set defaults based on language
	if [[ -z "$prefix" ]]; then
		case "$epub_lang" in
			ko) prefix='제' ;;
			zh) prefix='第' ;;
			ja) prefix='第' ;;
			es) prefix='Volumen ' ;;
			fr) prefix='Volume ' ;;
			de) prefix='' ;;
			ru) prefix='Том ' ;;
			*) prefix='Volume ' ;;
		esac
	fi
	if [[ -z "$suffix" ]]; then
		case "$epub_lang" in
			ko) suffix='권' ;;
			zh) suffix='卷' ;;
			ja) suffix='巻' ;;
			de) suffix='. Band' ;;
			*) suffix='' ;;
		esac
	fi

	toc_volume_prefix="$prefix"
	toc_volume_suffix="$suffix"
}

readonly xml_package_type="application/oebps-package+xml"
readonly xml_xmlns="urn:oasis:names:tc:opendocument:xmlns:container"
container_xml=$(cat <<EOF
<?xml version="1.0"?>
<container version="1.0" xmlns="$xml_xmlns">
   <rootfiles>
      <rootfile full-path="content.opf" media-type="$xml_package_type"/>
   </rootfiles>
</container>
EOF
)
readonly container_xml

ibooks_xml=$(cat <<'EOF'
<?xml version="1.0" encoding="UTF-8" ?>
<display_options>
  <platform name="*">
    <option name="specified-fonts">true</option>
  </platform>
</display_options>
EOF
)
readonly ibooks_xml

setup_base() {
	# Setup base ePUB structure from first file
	cp -r "0/META-INF" "0/mimetype" "."

	# Update container.xml to point to our new OPF
	echo "$container_xml" > META-INF/container.xml

	# Add iBooks display options if not present
	local ibooks="META-INF/com.apple.ibooks.display-options.xml"
	if [[ ! -f "$ibooks" ]]; then
		log "Adding iBooks display options"
		echo "$ibooks_xml" > "$ibooks"
	fi
}

merge_ncxs() {
	[[ -z "$first_ncx" ]] && return 0

	local uuid="$1" toc_file="$merged_ncx"
	local prefix="$toc_volume_prefix"
	local suffix="$toc_volume_suffix"

	# Initialize NCX with header
	{
		xml_grep_before_tag navMap "$first_ncx" \
			| sed -e "s/$uuid_pattern/$uuid/"
		echo "  <navMap>"
	} > "$toc_file"

	# Process each volume
	for i in "${!epub_files[@]}"; do
		debug_var ncx_files[i]
		[[ -z "${ncx_files[i]:-}" ]] && continue

		local cur_ncx cur_ncx_dir volume_num

		cur_ncx="${ncx_files[i]}"
		cur_ncx_dir="$(dirname "$cur_ncx")"
		volume_num=$((i + 1))

		if [[ -n "${toc_volume_labels[i]:-}" ]]; then
			local label="${toc_volume_labels[i]}"
		else
			local label="$prefix$volume_num$suffix"
		fi
		# Add volume entry
		# shellcheck disable=SC2129
		cat <<- EOF
			<navPoint id="volume-$i" playOrder="1">
				<navLabel>
					<text>$(escape_xml "$label")</text>
				</navLabel>
			EOF

		# Add volume link
		get_xml_element "content$sp*src$sp*=" "$cur_ncx" \
			| sed "s#$sp*src=$sp*.#&${cur_ncx_dir}/#"

		# Merge navigation points
		extract_and_modify_xml navMap "" "$cur_ncx_dir" "$i" "$cur_ncx"

		echo "</navPoint>"
	done | fix_playorder | normalize_path >> "$toc_file"

	echo -e "</navMap>\n</ncx>" >> "$toc_file"

	format_xml "$toc_file" > .x && mv .x "$toc_file"
}

merge_navs() {
	# Merge NAV files for ePUB 3.0
	[[ -z "$first_nav" ]] && return 0

	local prefix="$toc_volume_prefix"
	local suffix="$toc_volume_suffix"
	local nav_file="$merged_nav"

	# Initialize NAV with header
	{
		xml_grep_before_tag body "$first_nav" \
			| sed "s#href=.#&$(dirname "$first_nav")/#" 
		echo '<body>'
		echo '<nav epub:type="toc">'
		echo "<h1>$epub_title</h1><ol>"
	} > "$nav_file"

	# Process each volume
	for i in "${!epub_files[@]}"; do
		debug "nav_files[$i]=\"${nav_files[i]:-}\""
		[[ -z "${nav_files[i]:-}" ]] && continue

		local cur_nav cur_nav_dir volume_num ref

		cur_nav="${nav_files[i]}"
		cur_nav_dir="$(dirname "$cur_nav")"
		volume_num=$((i + 1))

		ref="$cur_nav_dir/$(get_xml_attr "a$sp*href" "href" "$cur_nav")"
		if [[ -n "${toc_volume_labels[i]:-}" ]]; then
			local label="${toc_volume_labels[i]}"
		else
			local label="$prefix$volume_num$suffix"
		fi

		# Add volume entry and link

		vol_link="<li style='list-style: none !important; margin: 0 !"
		vol_link+="important; padding: 0 !important;' id=\"vol-$i=\">"
		vol_link+="<a href=\"$ref\">$(escape_xml "$label")</a></li>"

		echo "$vol_link"

		# Merge navigation points
		extract_and_modify_xml nav "epub.type=.toc." \
				"$cur_nav_dir" "$i" "$cur_nav" \
			| grep -v '<h[0-6]'
	done >> "$nav_file"

	# Close NAV structure
	echo -e '</ol></nav>\n</body>\n</html>' >> "$nav_file"

	normalize_path "$nav_file" | format_xml > .x && mv .x "$nav_file"
}

merge_opfs() {
	# Merge all OPF manifests and spines
	debug_func "$@"
	local uuid="$1"
	local manifest_file="content.opf.manifest"
	local spine_file="content.opf.spine"

	# Initialize OPF with header
	gen_opf_header "${opf_files[0]}" "$epub_title" \
		| sed "s/$uuid_pattern/$uuid/" \
		> "content.opf"

	# Process each volume for manifest and spine
	for i in "${!epub_files[@]}"; do
		cur_opf="${opf_files[i]}"
		cur_opf_dir="$(dirname "$cur_opf")"

		# Extract and modify spine entries
		extract_and_modify_xml \
				"spine" "" "$cur_opf_dir" "$i" "$cur_opf" \
			>> "$spine_file"

		# Extract manifest entries with unique IDs and corrected paths.
		extract_and_modify_xml \
				"manifest" "" "$cur_opf_dir" "$i" "$cur_opf" \
			>> "$manifest_file"
	done

	if [[ ! -s "$manifest_file" && ! -s "$spine_file" ]]; then
		error "Failed to read <spine> or <manifest> in OPF file"
	fi

	# Assemble final OPF
	{
		echo "  <manifest>"
		if [[ -n "$first_nav" ]]; then
			# Add only one nav property
			nav_item="<item id=\"$merged_nav_id\" href=\""
			nav_item+="$merged_nav\" media-type=\"application/xhtml"
			nav_item+="+xml\" properties=\"nav\"/>"
			echo "$nav_item"
		fi

		# Remove all nav properties
		sed "s:$sp*properties$sp*=$sp*[\"']nav[^\"']*[\"']::" \
			"$manifest_file"

		echo "  </manifest>"

		if [[ -n "$first_ncx" ]]; then
			echo "<spine toc=\"$merged_ncx_id\">"
		else
			echo "<spine>"
		fi

		cat "$spine_file"
		echo -e "  </spine>\n</package>"
	} \
	| sed -E "
	s:\"0/[^\"']*\.ncx\":\"$merged_ncx\":
	s:\"${first_ncx_id}-0\":\"$merged_ncx_id\":
	s:\"${first_ncx_id}\":\"$merged_ncx_id\":" \
	| normalize_path  \
	| fix_font_paths \
	| filter_dups \
	| grep -ivE '[0-9][0-9]*/.*\.(ncx|otf|ttf|woff|woff2|eot)' \
	>> "content.opf"

	to_nfc content.opf | format_xml > .x && mv .x content.opf

	rm -f "$manifest_file" "$spine_file"
}

backup_originals() {
	# Backup original files for splitting
	debug_func
	mkdir -p .epub-merge

	local no_ncx="___no_ncx___"
	local no_nav="___no_nav___"
	local nav="$merged_nav"

	adjust_path() {
		local path="$1" idx="$2"
		echo "${path}/" | sed -E "s:^$idx/::; s://:/:; s:^$:.:"
	}

	for i in "${!epub_files[@]}"; do
		local cur_opf="${opf_files[i]}"
		local cur_ncx="${ncx_files[i]:-$no_ncx}"
		local cur_nav="${nav_files[i]:-$no_nav}"

		local new_opf_dir new_ncx_dir new_nav_dir
		new_opf_dir=$(adjust_path "$(dirname "$cur_opf")" "$i")
		new_ncx_dir=$(adjust_path "$(dirname "$cur_ncx")" "$i")
		new_nav_dir=$(adjust_path "$(dirname "$cur_nav")" "$i")

		local cur_ncx_id
		if [[ "$cur_ncx" != "$no_ncx" ]]; then
			cur_ncx_id=$(grep "$(basename "$cur_ncx")" "$cur_opf" \
				| sed -n -E 's/.*id="([^"]*)".*/\1/p')
		fi
		cur_ncx_id="${cur_ncx_id:-$no_ncx}"

		# OPF
		format_xml "$cur_opf" \
			| sed -E "
			s:<(item|reference).*href=[\"']:&$new_opf_dir/:g
			s:(<(item|reference).*href=.*)(//):\1/:
			s:href=\"[^\"]*\.ncx\":href=\"toc.ncx\":
			s:href=\"[^\"]*$(basename "$cur_nav")\":href=\"$nav\":
			s:[\"']${cur_ncx_id}[\"']:\"ncx\":" \
			| normalize_path \
			| fix_font_paths \
			> ".epub-merge/$i.opf"

		# NCX
		if [[ "$cur_ncx" != "$no_ncx" ]]; then
			format_xml "$cur_ncx" \
				| sed -E "
				s:src=\":&$new_ncx_dir/:g
				s:(src=.*)(//):\1/:
				s:src=\"[^\"]*$(basename \
					"$cur_nav")\":href=\"$nav\":" \
				| normalize_path \
				> ".epub-merge/$i.ncx"
		fi

		# NAV
		if [[ "$cur_nav" != "$no_nav" ]]; then
			format_xml "$cur_nav" \
				| sed -E "
				s:(href=\")([^#]):\1$new_nav_dir/\2:g
				s:(href=.*)(//):\1/:
				s:href=\"[^\"]*$(basename \
					"$cur_nav")\":href=\"$nav\":" \
				| normalize_path \
				> ".epub-merge/$i.nav"
		fi

		# Filename
		basename "${epub_files[i]}" | to_nfc > ".epub-merge/$i.name"
	done
}

consolidate_merged() {
	# Consolidate merged archive, and remove unused
	debug_func "*@"

	# Move all font files to central location
	mkdir fonts

	find [0-9]* -type f \( \
		-iname "*.ttf" -o -iname "*.otf" \
		-o -iname "*.woff*" -o -iname "*.eot" \) \
		-exec mv {} fonts/ \; 2> /dev/null || true
	rmdir fonts 2> /dev/null || true

	# Remove unused
	find [0-9]* \( -iname "META-INF" -o -iname "mimetype" \
		-o -iname "*.opf" -o -iname "*.ncx" \) \
		-exec rm -rf {} + 2> /dev/null || true

	find [0-9]* -type d -empty -delete || true
}

path_to_root() {
	# Calculate relative path to root
	local parent
	parent="$(dirname "$1" | sed 's:^\./::')"

	if [ "$parent" = "." ]; then
		echo "."
	else
		# shellcheck disable=SC2001
		echo "$parent" | sed 's#[^/][^/]*#..#g'
	fi
}

fix_fontpaths_to_root() {
	# Update CSS font URLs for merged ePUB
	# Merged, so one depth more
	sed_expr="s#url$sp*\([^)]*/([^/]+\.(ttf|otf|woff|woff2|eot))[^)]*\)#url"
	sed_expr+="($(path_to_root "$1")/fonts/\\1)#i"
	sed_i -E "$sed_expr" "$1"
}

path_to_trunk() {
	# Calculate relative path to trunk (one level below root)
	local parent
	parent="$(dirname "$(dirname "$1" | sed -e 's:^\./::')")"

	if [ "$parent" = "." ]; then
		echo ""
	else
		echo "$parent/" | sed 's#[^/][^/]*#..#g'
	fi
}

fix_fontpaths_to_trunk() {
	# Update CSS font URLs for split ePUBs
	# Trunk dirs(0, 1, 2, ...) are now root
	sed_expr="s#url$sp*\([^)]*/([^/]+\.(ttf|otf|woff|woff2|eot))[^)]*\)#" 
	sed_expr+="url($(path_to_trunk "$1")fonts/\\1)#i"
	sed_i -E "$sed_expr" "$1"
}

update_css_fonts_for_split() {
	# Update CSS font URLs for split ePUB (digits/path -> ../fonts/)
	debug_func "*@"
	find . -type f -iname "*.css" -print0 | while IFS= read -r -d '' css; do
		fix_fontpaths_to_trunk "$css"
	done
}

update_css_fonts_for_merge() {
	# Update CSS font URLs for merged ePUB (paths -> fonts/)
	debug_func "*@"
	find . -type f -iname "*.css" -print0 | while IFS= read -r -d '' css; do
		# New path from css to font is the concatenation of path from 
		# css to altered root and altered font path (/fonts)
		fix_fontpaths_to_root "$css"
	done
}

create_final_epub() {
	# Create final ePUB file
	debug_func "$@"
	local output_realpath="$1"
	local working_dir="$2"
	local fonts_parent_dir="${3:-}"

	# Package ePUB with proper compression
	cd "$working_dir" > /dev/null
	rm -f "$temp_epub"
	zip -q -X0 "$temp_epub" mimetype
	zip -q -Xr9D "$temp_epub" . -x mimetype -x "*/.DS_Store" -x "__MACOSX/*"

	if [[ -n "$fonts_parent_dir" ]]; then
		debug_var fonts_parent_dir
		cd - > /dev/null
		cd "$fonts_parent_dir/" > /dev/null
		if [[ -d "$fonts_parent_dir/fonts" ]]; then
			zip -q -r "$temp_epub" "fonts/"
		fi
		cd - > /dev/null
	fi

	cd - > /dev/null
	if mv -f "$temp_epub" "$output_realpath"; then
		log "$(basename "$output_realpath"): successfully created"
		return 0
	else
		log "$(basename "$output_realpath"): failed to create"
		return 1
	fi
}

create_individual_epubs() {
	# Create individual ePUB files from extracted merged ePUB
	local status=0 count i
	local toc_file="toc.ncx" nav_file="nav.xhtml"

	find fonts -type f | sort -V | sed 's#^..##' \
		> .all-fonts-list 2> /dev/null || true

	# shellcheck disable=SC2012
	count="$(ls .epub-merge/[0-9]*.opf 2> /dev/null | wc -l)"

	for i in $(seq 0 $((count - 1))); do
		local cur_epub
		cur_epub="$(cat ".epub-merge/$i.name")"

		if [[ $overwrite_existing != 1 && \
			-f "$output_dir/$cur_epub" ]]; then
			status=1
			orange_log "$cur_epub: already exists"
			continue
		fi

		cp -r META-INF mimetype "$i"/
		cp .epub-merge/"$i".opf "$i"/content.opf
		[[ -f .epub-merge/"$i".ncx ]] \
			&& cp .epub-merge/"$i".ncx "$i/$toc_file"
		[[ -f .epub-merge/"$i".nav ]] \
			&& cp .epub-merge/"$i".nav "$i/$nav_file"

		grep -v '<!--' "$i"/content.opf \
			| sed -n 's/.*href="\(fonts\/[^"]*\)".*/\1/p' \
			| sort -V > .fonts-list || true

		local different_fonts=""

		if ! diff .fonts-list .all-fonts-list > /dev/null 2>&1; then
			different_fonts=1
		fi

		local output="$output_dir/$cur_epub"

		if [[ $different_fonts == 1 ]]; then
			mkdir "$i/fonts"
			sed "s#.*#cp \"&\" $i/fonts/#" .fonts-list | bash - 
			if ! create_final_epub "$output" "$i/"; then
				status=1
			fi
			rmdir fonts 2> /dev/null || true
		else
			if ! create_final_epub "$output" "$i/" "."; then
				status=1
			fi
		fi

		cd "$temp_dir" > /dev/null
	done

	return $status
}

extract_merged_epub() {
	# Extract merged ePUB and split into original files
	debug_func "$@"
	if ! validate_epub "$1" 1; then
		error "Program exits"
	fi

	# `mktemp` should be done before extracting args
	temp_dir="$(mktemp -d)"

	unzip -q "$1" -d "$temp_dir"

	# `cd` should be done after extracting args
	cd "$temp_dir" > /dev/null

	# Update font paths in all CSS files to point to centralized fonts 
	update_css_fonts_for_split

	create_individual_epubs
}

check_epub_versions() {
	# Verify all ePUB files have same version
	debug_func "$@"
	local first_version
	first_version="$(get_version "$1")"

	if [[ -z "$first_version" || \
		( "$first_version" != "2.0" && \
		"$first_version" != "3.0" ) ]]; then
	error "Failed to get ePUB version ($1)"
	fi

	if [[ -z "$first_version" \
			|| ( "$first_version" != "2.0" 
				&& "$first_version" != "3.0" ) ]]; then
		error "Failed to get ePUB version ($1)"
	fi

	local files=("$@")
	if (( ${#files[@]} <= 1 )); then
		echo "$first_version"
		return 0
	fi

	local remaining_files=("${files[@]:1}")

	for epub in "${remaining_files[@]}"; do
		epub_version="$(get_version "$epub")"
		if [[ "$epub_version" != "$first_version" ]]; then
			ver="$1 -> '$first_version', $epub -> '$epub_version'"
			error "Different ePUB versions ($ver)"
		fi
	done

	echo "$first_version"
}

trap 'printf "\033[31mError (epub-merge): at line $LINENO\033[0m\n" >&2; \
	cleanup' ERR INT TERM
trap cleanup EXIT

main() {
	parse_args "$@"
	shift $((OPTIND-1))

	# Check if unzip, zip, and uuidgen installed
	check_deps || error "Program exits"

	# Validate command line arguments
	validate_args "$@"

	# Check ePUBs versions
	epub_version="$(check_epub_versions "$@")"
	readonly epub_version

	debug_var epub_version
	temp_epub="$(mktemp "${output_dir}/.epub-merge.XXXXX")"
	readonly temp_epub

	if [[ -n "$extract_mode" ]]; then
		extract_merged_epub "$1" && exit 0 || exit 1
	fi

	# Determine output filename and epub title
	gen_output_names "$1" "$2"

	# Validate all ePUB files, check if output file name conflicts
	# with an input file, and more.
	for epub in "$@"; do
		validate_epub "$epub" 0

		if [[ "$(realpath "$epub" | tr '[A-Z]' '[a-z]')" \
			== "$(echo "$output_dir/$epub_name.epub" \
				| tr '[A-Z]' '[a-z]')" ]]; then
			error "output file name ($epub_name.epub) conflicts" \
				"with an input file."
		fi

		if [[ "$filename_label_given" -eq 1 ]]; then
			toc_volume_labels+=("${epub%.epub}")
		fi
	done

	# Sort input files and save them to epub_files
	sort_files "$@"

	# Create temporary directory
	temp_dir="$(mktemp -d)"

	# Extract all ePUBs to 0/, 1/, 2/, ... in temp_dir
	extract_files

	# Now, we move to working directory
	cd "$temp_dir" > /dev/null

	# Get paths lists OPF/NCX/nav_files
	collect_file_paths_and_format_xml

	# Setup base structure (mimetype, META-INF/*, ...)
	setup_base

	# Detect language
	epub_lang="$(detect_lang "${opf_files[0]}" "$epub_lang")"
	readonly epub_lang
	get_valume_labels

	local uuid
	uuid="$(uuidgen)"

	# Generate NCX/NAV/OPF
	merge_navs
	merge_ncxs "$uuid"
	merge_opfs "$uuid"

	# Backup [0-9]*/**/*.(opf|ncx|nav) to ".epub-merged/"
	backup_originals

	# Consolidate merged archive and remove unused
	consolidate_merged

	# Update CSS font references
	update_css_fonts_for_merge

	create_final_epub "$output_dir/$epub_name.epub" "."
}

if [ -z "${EPUB_MERGE_TEST:-}" ]; then
	main "$@"
fi
