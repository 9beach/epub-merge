#!/bin/bash

# epub-merge - combines multiple ePUB files into a single volume, or 
# extracts merged ePUB files

set -euo pipefail

if [[ "$OSTYPE" == "darwin"* ]]; then
	sed_i() {
		sed -i '' "$@"
	}
else
	sed_i() {
		sed -i "$@"
	}
fi

# Error handler for ERR, INT, and TERM signals
trap 'printf "\033[31mError (epub-merge): at line $LINENO\033[0m\n" >&2; \
	cleanup' ERR INT TERM

# Cleanup temp files on exit
cleanup() {
	if [[ -f "${TEMP_EPUB:-}" ]]; then
		rm -f "$TEMP_EPUB"
	fi
	if [[ -d "${TEMP_DIR:-}" ]]; then
		rm -rf "$TEMP_DIR"
	fi
}

trap cleanup EXIT

# Display usage information
show_usage() {
	cat >&2 << 'EOF'
NAME
     epub-merge -- merge multiple ePUB files into one or extract merged ePUB

SYNOPSIS
     epub-merge [-fOq] [-d directory] [-l lang] [-p prefix] [-s suffix]
                [-t title] [-v labels] file ...
     epub-merge -x file

DESCRIPTION
     The epub-merge utility combines multiple ePUB files into a single volume
     or extracts a previously merged ePUB back into its original components.

     The options are as follows:

     -d directory
             Specify the output directory for generated ePUB files.  The
             default is the current directory.

     -f      Force overwrite of existing files with the same name.

     -l lang
             Specify the language code for the merged ePUB (e.g., ko, en, ja,
             zh, ru).

     -O      Disable natural sorting of input files.

     -p prefix
             Add a prefix to table of contents volume labels.

     -q      Quiet mode.  Suppress progress messages.

     -s suffix
             Add a suffix to table of contents volume labels.

     -t title
             Set a custom title for the merged ePUB.  This title is also used
             as the output filename.

     -v labels
             Set custom table of contents volume labels for each volume.
             Labels must be separated by semicolons, for example:
             "Love;Peace;Hate".

     -x      Extraction mode.  Split a merged ePUB back into its original
             component files.

EXAMPLES
     Merge three ePUB files with natural sorting (default):

           $ epub-merge love-10.epub love-8.epub love-9.epub
           extracting love-8.epub
           extracting love-9.epub
           extracting love-10.epub
           love.epub: successfully created

     Extract a merged ePUB back into original files:

           $ epub-merge -x love.epub
           love-8.epub: successfully created
           love-9.epub: successfully created
           love-10.epub: successfully created

     Merge files in the order specified (disable natural sorting):

           $ epub-merge -O love-10.epub love-8.epub love-9.epub
           extracting love-10.epub
           extracting love-8.epub
           extracting love-9.epub
           love.epub: successfully created

     Merge with custom title and filename:

           $ epub-merge -t "Arabian Nights: Tales of 1,001 Nights" a?.epub
           Extracting a1.epub
           Extracting a2.epub
           Extracting a3.epub
           Arabian Nights_ Tales of 1,001 Nights.epub: successfully created
EOF
}

# Global variables
OUTPUT_DIR="$(realpath "$(pwd)")"
EPUB_VERSION=""
EPUB_FILES=() 
OPF_FILES=()
NCX_FILES=()
NAV_FILES=()

FIRST_NCX_ID=""
FIRST_NCX=""
readonly MERGED_NCX_ID="ncx"
readonly MERGED_NCX_FILE="toc.ncx"

FIRST_NAV_ID=""
FIRST_NAV=""
readonly MERGED_NAV_ID="nav"
readonly MERGED_NAV_FILE="nav.xhtml"

TEMP_DIR=""
TEMP_EPUB=""
OVERWRITE_EXISTING=""
TOC_VOLUME_PREFIX=""
TOC_VOLUME_SUFFIX=""
TOC_VOLUME_PREFIX_SUFFIX_GIVEN=""
TOC_VOLUME_LABELS=()
EPUB_NAME="" 
EPUB_TITLE=""
EPUB_LANG=""
DO_NOT_SORT_PARAMS=""
EXTRACT_MODE=""

DEBUG=${DEBUG:-}
QUIET=""

# --- Logging functions

log() {
	if [[ -z "$QUIET" ]]; then
		printf '\033[90m%s\033[0m\n' "$*" >&2
	fi
}

orange_log() {
	if [[ -z "$QUIET" ]]; then
		printf '\033[38;5;208m%s\033[0m\n' "$*" >&2
	fi
}

debug() {
	if [[ -n "$DEBUG" ]]; then
		printf "\033[34m[DEBUG] ${BASH_LINENO[1]} %s\033[0m\n" "$*" >&2
	fi
}

debug_var() {
	debug "$1=\"${!1}\""
}

debug_func() {
	if [ "${1:-}" != "$*" ]; then
		local joined
		joined=$(IFS=,; echo "$*")
		debug "function: ${FUNCNAME[2]} / ${FUNCNAME[1]} ($joined)"
	else
		debug "function: ${FUNCNAME[2]} / ${FUNCNAME[1]}"
	fi
}

error() {
	printf "\033[31mError (epub-merge): %s\033[0m\n" "$*" >&2
	exit 1
}

# --- XML utility functions

XML_FORMATTER=""

if command -v xmllint &> /dev/null; then
	XML_FORMATTER="xmllint"
elif command -v python3 &> /dev/null; then
	XML_FORMATTER="python3"
else
	XML_FORMATTER="cat"
	log "The XML formatter is not installed, which may cause errors during the merge process. Please install xmllint."
fi

# Format XML/HTML file
if [[ "$XML_FORMATTER" == "xmllint" ]]; then
	format_xml() {
		local file="$1"
		local temp_xml="$TEMP_DIR/.xml.XXXXX"
		xmllint --recover --format --noblanks "$file" \
			> "${temp_xml}" 2>/dev/null \
			&& mv "${temp_xml}" "$file"
	}
elif [[ "$XML_FORMATTER" == "python3" ]]; then
	format_xml() {
		local file="$1"
		local temp_xml="$TEMP_DIR/.xml.XXXXX"
		python3 -c "import xml.dom.minidom as x,sys; print(x.parseString(open(sys.argv[1]).read()).toprettyxml(indent='    '))" "$file" 2>/dev/null \
			| grep -v "^ *$" \
			> "${temp_xml}" \
			&& mv "${temp_xml}" "$file"
	}
else
	format_xml() {
		log "XML formatter not available"
	}
fi

# Split XML elements for easier processing
split_xml() {
	tr -d '\n' < "${1:-/dev/stdin}" | sed 's/</\n</g'
}

# Extract attribute value from XML pattern
get_xml_attr() {
	debug_func "$@"
	local pattern="$1" attr="$2"

	sed -nE "\|${pattern}| {
		s|.*${attr}=[\"']([^\"']*)[\"'].*|\1|p;
		q
	}" ${3:+"$3"}
}

# Escape XML characters
escape_xml_for_sed() {
	# Safe for `sed` replacement strings
	printf '%s' "${1-}" | sed \
		-e 's/\\/\\\\/g' \
		-e 's/&/\\\&amp;/g' \
		-e 's/</\\\&lt;/g' \
		-e 's/>/\\\&gt;/g' \
		-e 's/"/\\\&quot;/g' \
		-e "s/'/\\\&apos;/g" \
		-e 's/\//\\\//g'
}

escape_xml() {
	printf '%s' ${1:+"$1"} | sed \
		-e 's/&/\&amp;/g' \
		-e 's/</\&lt;/g' \
		-e 's/>/\&gt;/g' \
		-e 's/"/\&quot;/g' \
		-e "s/'/\&apos;/g"
}

# Extract XML element by pattern
get_xml_element() {
	debug_func "$@"
	local pattern="$1"

	sed -nE "
		/<[^>]*${pattern}[^>]*>/ {
			s#.*(<[^>]*${pattern}[^>]*>)#\1#p;
			q
		}" ${2:+"$2"}
}

# Extract content between XML tags and modify paths/IDs
extract_and_modify_xml() {
	debug_func "$@"
	local tag="$1" pattern="$2" dir="$3" suffix="$4"

	sed -E "
	/<${tag}[^>]*${pattern}[^>]*>/,/<\/${tag}/!d
	/<\/?${tag}/d
	/^$/d
	s:(src|href)=\":&$dir/:g
	s:(id|idref)=\"[^\"]*:&-${suffix}:g
	" ${5:+"$5"}
}

# Extract content before specified tag
xml_grep_before_tag() {
	debug_func "$@"
	local tag_name="$1"

	sed -E "/<\/*${tag_name}[^>]*>/,\$d" ${2:+"$2"}
}

# Modify OPF metadata: replace title and append suffix('-0') to cover ID
modify_opf_metadata() {
	debug_func "$@"
	local epub_title="$1"
	sed -E "
	s|(<dc:title[^>]*>).*</dc:title>|\1$epub_title</dc:title>|
	/name=\"cover\"/s|content=\"[^\"]*|&-0|
	" \
	| grep -viE 'calibre:(series|title_sort)'
}

# Remove duplicate manifest font items from stdin (keep first occurrence only)
filter_dups() {
	awk '
	/<manifest/ { in_manifest = 1 }
	/<\/manifest/ { in_manifest = 0; print; next }

	in_manifest && /<item[^>]*href=/ {
		if (match($0, /href=["'\'']([^"'\'']*)["'\'']/)) {
			href = substr($0, RSTART + 6, RLENGTH - 7)

			if (href != "") {
				href_lower = tolower(href)

				if (href_lower ~ /\.(ttf|otf|woff|woff2|eot)(\?|$)/) {
					if (seen[href_lower]) {
						next
					}
					seen[href_lower] = 1
				}
			}
		}
	}

	{ print }
	'
}

# --- ePUB utility functions

# Get ePUB version from file
get_version() {
	local epub="$1" opf_path
	opf_path="$(unzip -p "$epub" META-INF/container.xml \
		| get_xml_attr full-path full-path)"

	debug_var epub
	debug_var opf_path

	[ -z "$opf_path" ] && return 1

	unzip -p "$epub" "$opf_path" \
		| split_xml \
		| get_xml_attr 'package.*version' version
}

# Check system dependencies
check_deps() {
	local missing_deps=()

	for cmd in unzip zip uuidgen; do
		if ! command -v "$cmd" >/dev/null 2>&1; then
			missing_deps+=("$cmd")
		fi
	done

	if [[ ${#missing_deps[@]} -gt 0 ]]; then
		log "Missing required commands '${missing_deps[*]}'"
		return 1
	fi
}

# Extract common prefix from filenames
get_prefix() {
	debug_func "$@"
	local file1="$1" file2="$2"
	local base1
	base1="$(basename "$file1")" base2="$(basename "$file2")"
	local common=""
	local min_length
	min_length=$((${#base1} < ${#base2} ? ${#base1} : ${#base2}))

	for ((i=0; i<min_length; i++)); do
		if [[ "${base1:i:1}" == "${base2:i:1}" ]]; then
			common+="${base1:i:1}"
		else
			break
		fi
	done

	# Remove trailing numbers, brackets, and separators
	echo "$common" | sed -e 's/[-_[( ]*$//' -e 's/ [0-9][0-9]*$//'
}

# Check if iconv supports UTF-8-MAC
ICONV_HAS_UTF_8_MAC="$(iconv -l | grep "UTF-8-MAC" || true)"
readonly ICONV_HAS_UTF_8_MAC

# Convert to NFC encoding
to_nfc(){
	if [ -n "$ICONV_HAS_UTF_8_MAC" ]; then
		iconv -f UTF-8-MAC -t UTF-8 "$1" > "$1.nfc" 2>/dev/null \
			&& mv "$1.nfc" "$1"
	fi
}

# --- ePUB validation and processing functions

# Validate ePUB structure
validate_epub() {
	debug_func "$@"
	local epub_file="$1" is_merged="${2:-}" temp_file
	temp_file="$(mktemp)"

	if ! unzip -l "$epub_file" > "$temp_file"; then
		log "Invalid ZIP file '$epub_file'"
		rm -f "$temp_file"
		return 1
	fi

	if ! grep -qEi "(mimetype|META-INF/container.xml|\.opf)$" \
			"$temp_file"; then
		log "Missing required file '$pattern' in '$epub_file'"
		rm -f "$temp_file"
		return 1
	fi

	if [[ "$is_merged" == 1 ]]; then
		local merged_opf_count opf_backup_count
		merged_opf_count="$(grep -c " content.opf" "$temp_file"|| true)"
		opf_backup_count="$(grep -cE "merge/[0-9]+.opf$" "$temp_file" \
			|| true)"

		if [[ "$merged_opf_count" -ne 1 \
			|| "$opf_backup_count" -lt 2 \
		]]; then
			log "'$epub_file' is not a valid merged ePUB"
			rm -f "$temp_file"
			return 1
		fi
	fi

	rm -f "$temp_file"
}

# Fix NCX playOrder attributes
fix_playorder() {
	local mark_done="aqswde"
	# Re-sequence playOrder attributes for proper navigation
	awk -v regex="playOrder=\"[0-9][0-9]*\"" -v prefix="${mark_done}=\"" \
		-v suffix="\"" '
	{
		while (match($0, regex)) {
			$0 = substr($0, 1, RSTART-1) \
				prefix (++count) \
				suffix \
				substr($0, RSTART+RLENGTH)
			}
		print $0;
	}
	' \
	| sed "s/${mark_done}/playOrder/g"
}

# Generate OPF header section
gen_opf_header() {
	debug_func "$@"
	local opf_file="$1"
	local epub_title="$2"

	xml_grep_before_tag manifest "$opf_file" \
		| modify_opf_metadata "$epub_title"
}

# Fix font paths for merged ePUB
# ='path/to/myfont.TTF' -> ='fonts/myfont.TTF'
fix_font_paths() {
	sed -E 's#href=["'"'"'].*/[^"'"'"']*/([^/]+\.(ttf|otf|woff|woff2|eot))["'"'"']#href="fonts/\1"#gi'
}

safe_filename() {
	echo "$1" | tr '/:*?<>|"\\' '_'
}

# --- Command line parsing and validation
# Writes: many variables
parse_args() {
	while getopts "n:t:l:p:v:s:d:fOqx" opt; do
		case "$opt" in
			f) OVERWRITE_EXISTING=1 ;;
			d) OUTPUT_DIR="$(realpath "$OPTARG")" ;;
			n) EPUB_NAME="$OPTARG" ;;
			v)
				IFS=';' read -a _labels <<< "$OPTARG"
				for l in "${_labels[@]}"; do
					TOC_VOLUME_LABELS+=("$l")
				done
				;;
			t) EPUB_TITLE="$OPTARG" ;;
			l) EPUB_LANG="$OPTARG" ;;
			p) TOC_VOLUME_PREFIX="$OPTARG"
			   TOC_VOLUME_PREFIX_SUFFIX_GIVEN=1 ;;
			s) TOC_VOLUME_SUFFIX="$OPTARG"
			   TOC_VOLUME_PREFIX_SUFFIX_GIVEN=1 ;;
			O) DO_NOT_SORT_PARAMS=1 ;;
			q) QUIET=1 ;;
			x) EXTRACT_MODE=1 ;;
			\?) show_usage; exit 1 ;;
		esac
	done

	readonly OUTPUT_DIR
	readonly OVERWRITE_EXISTING
	readonly DO_NOT_SORT_PARAMS
	readonly QUIET
	readonly EXTRACT_MODE
	readonly TOC_VOLUME_PREFIX_SUFFIX_GIVEN
}

validate_args() {
	if [[ -n "$EXTRACT_MODE" ]]; then
		if [[ $# -ne 1 ]]; then
			show_usage
			exit 1
		fi
	elif [[ $# -lt 2 ]]; then
		show_usage
		exit 1
	fi

	for file in "$@"; do
		[[ -f "$file" ]] || error "File not found '$file'"
	done
}

# Generate output filename and title from input files
gen_output_names() {
	EPUB_NAME="${EPUB_TITLE:-$EPUB_NAME}"
	if [[ -z "$EPUB_NAME" ]]; then
		EPUB_NAME="$(get_prefix "$(basename "$1")" "$(basename "$2")")"
	fi

	if [[ -z "$EPUB_NAME" ]]; then
		error "Cannot determine output name from '$1' and '$2'.\nPlease use -n option"
	fi

	EPUB_TITLE="${EPUB_TITLE:-$EPUB_NAME}"

	EPUB_NAME="$(safe_filename "$EPUB_NAME")"
	EPUB_TITLE="$(escape_xml_for_sed "$EPUB_TITLE")"

	if [[ $OVERWRITE_EXISTING != 1 && -f "$EPUB_NAME.epub" ]]; then
		error "$EPUB_NAME.epub: already exists"
	fi
}

# Sort input files naturally unless disabled
sort_files() {
	if [[ -n "${DO_NOT_SORT_PARAMS:-}" ]]; then
		EPUB_FILES=("$@")
	else
		local sorted_files=()
		while IFS= read -r -d '' file; do
			sorted_files+=("$file")
		done < <(printf "%s\0" "$@" | sort -zV)
		EPUB_FILES=("${sorted_files[@]}")
	fi
}

# Extract all ePUB files to numbered directories
extract_files() {
	for i in "${!EPUB_FILES[@]}"; do
		log "Extracting ${EPUB_FILES[i]}"
		mkdir -p "$TEMP_DIR/$i"
		unzip -q "${EPUB_FILES[i]}" -d "$TEMP_DIR/$i" \
			|| error "Failed to extract '${EPUB_FILES[i]}'"
	done
}

# Detect language from OPF content
# # Detect language from OPF content
detect_language() {
	debug_func "$@"
	local opf_file="$1" lang="$2"

	if [[ -n "$lang" ]]; then
		echo "$lang"
		return
	fi

	# Extract language from metadata first
	local lang_from_opf
	lang_from_opf=$(grep -ho -E -m1 '<dc:language>.*</dc:language>' \
			"$opf_file" 2>/dev/null \
		| sed 's/<[^>]*>//g')

	if [[ -n "$lang_from_opf" ]]; then
		echo "$lang_from_opf"
		return
	fi

	debug "auto-detect language"

	# Detect language by character patterns in a single grep call
	local char
	char=$(grep -o -E -m1 '[가-힣]|[ぁ-ゟァ-ヿ]|[一-龯]|[А-Яа-яЁё]' \
		"$opf_file" 2>/dev/null)
	case "$char" in
		[가-힣]*) echo "ko" ;;
		[ぁ-ゟァ-ヿ]*) echo "ja" ;;
		[一-龯]*) echo "zh" ;;
		[А-Яа-яЁё]*) echo "ru" ;;
		*) echo "en" ;;
	esac
}

# Collect OPF/NCX/NAV file paths, and format XML
collect_file_paths_and_format_xml() {
	for i in "${!EPUB_FILES[@]}"; do
		local cur_epub="${EPUB_FILES[i]}"

		# Get OPF path
		local cur_opf opf_dir cur_ncx cur_nav
		cur_opf="$(get_xml_attr full-path full-path "$i/META-INF/container.xml")"
		opf_dir="$(dirname "$cur_opf")"

		debug_var cur_opf

		[[ -n "$cur_opf" || ! -f "$i/$cur_opf" ]] \
			|| error "Can't find OPF in container.xml of $cur_epub"

		cur_opf="$i/$cur_opf"

		format_xml "$cur_opf"

		OPF_FILES[i]="$cur_opf"

		# Get NCX
		cur_ncx="$(get_xml_attr "x-dtbncx" "href" "$cur_opf")"
		
		debug_var cur_ncx
		if [[ -f "$i/$opf_dir/$cur_ncx" ]]; then
			format_xml "$i/$opf_dir/$cur_ncx"
		else
			cur_ncx=""
		fi

		if [[ -z "$FIRST_NCX_ID" && -n "$cur_ncx" ]]; then
			FIRST_NCX_ID="$(get_xml_attr \
				"$cur_ncx" "id" "$cur_opf")"
			FIRST_NCX="$i/$opf_dir/$cur_ncx"
		fi

		NCX_FILES[i]="${cur_ncx:+$i/$opf_dir/$cur_ncx}"

		[[ $EPUB_VERSION == "2.0" ]] && continue

		# Get NAV (ePUB 3.0 only)
		cur_nav="$(get_xml_attr \
			"properties=.nav." "href" "$cur_opf")"

		if [[ ! -f "$i/$opf_dir/$cur_nav" ]]; then
			cur_nav=""
		else
			format_xml "$i/$opf_dir/$cur_nav"
		fi

		if [[ -z "$FIRST_NAV_ID" && -n "$cur_nav" ]]; then
			FIRST_NAV_ID="$(get_xml_attr \
				"$cur_nav" "id" "$cur_opf")"
			FIRST_NAV="$i/$opf_dir/$cur_nav"
		fi

		NAV_FILES[i]="${cur_nav:+$i/$opf_dir/$cur_nav}"
	done
}

# Detect volume labels based on language
detect_volume_labels() {
	debug_func
	local lang="$EPUB_LANG"
	local prefix="$TOC_VOLUME_PREFIX"
	local suffix="$TOC_VOLUME_SUFFIX"

	if [[ -n "$TOC_VOLUME_PREFIX_SUFFIX_GIVEN" ]]; then
		return
	fi

	# Set defaults based on language
	if [[ -z "$prefix" ]]; then
		case "$lang" in
			ko) prefix='제 ' ;;
			zh) prefix='第' ;;
			ja) prefix='第' ;;
			es) prefix='Volumen ' ;;
			fr) prefix='Volume ' ;;
			de) prefix='' ;;
			ru) prefix='Том ' ;;
			*) prefix='Volume ' ;;
		esac
	fi
	if [[ -z "$suffix" ]]; then
		case "$lang" in
			ko) suffix='권' ;;
			zh) suffix='卷' ;;
			ja) suffix='巻' ;;
			de) suffix='. Band' ;;
			*) suffix='' ;;
		esac
	fi

	TOC_VOLUME_PREFIX="$prefix"
	TOC_VOLUME_SUFFIX="$suffix"
}

# Setup base ePUB structure from first file
setup_base() {
	debug_func
	local first_extract="0"

	# Copy base files
	cp -r "$first_extract/META-INF" "$first_extract/mimetype" "."

	# Update container.xml to point to our new OPF
	cat > META-INF/container.xml << EOF
<?xml version="1.0"?>
<container version="1.0" xmlns="urn:oasis:names:tc:opendocument:xmlns:container">
   <rootfiles>
      <rootfile full-path="content.opf" media-type="application/oebps-package+xml"/>

   </rootfiles>
</container>
EOF

	# Add iBooks display options if not present
	local ibooks="META-INF/com.apple.ibooks.display-options.xml"
	if [[ ! -f "$ibooks" ]]; then
		log "Adding iBooks display options"
		cat > "$ibooks" << EOF
<?xml version="1.0" encoding="UTF-8" ?>
<display_options>
  <platform name="*">
    <option name="specified-fonts">true</option>
  </platform>
</display_options>
EOF
	fi
}

readonly SED_REMOVE_DOT_PATH='s#(["/])\./#\1#g'
readonly SED_REMOVE_DOTDOT_PATH="s#/[^/][^/]*/\.\./#/#g"
readonly UUID_PATTERN='[0-9a-fA-F]\{8\}-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{12\}'

merge_ncxs() {
	debug_func "$@"
	local uuid="$1"

	[[ -z "$FIRST_NCX" ]] && return 0

	local prefix="$TOC_VOLUME_PREFIX"
	local suffix="$TOC_VOLUME_SUFFIX"
	local toc_file="$MERGED_NCX_FILE"

	# Initialize NCX with header
	{
		xml_grep_before_tag navMap "$FIRST_NCX" \
			| sed -e "s/$UUID_PATTERN/$uuid/"
		echo "  <navMap>"
	}  > "$toc_file"

	# Process each volume
	for i in "${!EPUB_FILES[@]}"; do
		debug_var NCX_FILES[i]
		[[ -z "${NCX_FILES[i]:-}" ]] && continue

		local cur_ncx cur_ncx_dir volume_num

		cur_ncx="${NCX_FILES[i]}"
		cur_ncx_dir="$(dirname "$cur_ncx")"
		volume_num=$((i + 1))

		if [[ -n "${TOC_VOLUME_LABELS[i]:-}" ]]; then
			local label="${TOC_VOLUME_LABELS[i]}"
		else
			local label="$prefix$volume_num$suffix"
		fi
		# Add volume entry
		# shellcheck disable=SC2129
		cat << EOF
  <navPoint id="volume-$i" playOrder="1">
    <navLabel>
      <text>$(escape_xml "$label")</text>
    </navLabel>
EOF

		# Add volume link
		get_xml_element 'content[[:space:]]*src[[:space:]]*=' \
				"$cur_ncx" \
			| sed "s#[[:space:]]*src=[[:space:]]*.#&${cur_ncx_dir}/#"

		# Merge navigation points
		extract_and_modify_xml navMap "" "$cur_ncx_dir" "$i" "$cur_ncx"

		echo "  </navPoint>"
	done \
	| fix_playorder \
	| sed -E "
	$SED_REMOVE_DOT_PATH
	$SED_REMOVE_DOTDOT_PATH" \
	>> "$toc_file"

	echo -e "  </navMap>\n</ncx>" >> "$toc_file"

	format_xml "$toc_file"
}

# Merge NAV files for ePUB 3.0
merge_navs() {
	debug_func
	# No nav
	[[ -z "$FIRST_NAV" ]] && return 0

	local prefix="$TOC_VOLUME_PREFIX"
	local suffix="$TOC_VOLUME_SUFFIX"
	local nav_file="$MERGED_NAV_FILE"

	# Initialize NAV with header
	{
		xml_grep_before_tag body "$FIRST_NAV" \
			| sed "s#href=.#&$(dirname "$FIRST_NAV")/#" 
		echo '<body>'
		echo '<nav epub:type="toc">'
		echo "<h1>$EPUB_TITLE</h1><ol>"
	} > "$nav_file"

	# Process each volume
	for i in "${!EPUB_FILES[@]}"; do
		debug "NAV_FILES[$i]=\"${NAV_FILES[i]:-}\""
		[[ -z "${NAV_FILES[i]:-}" ]] && continue

		local cur_nav cur_nav_dir volume_num ref

		cur_nav="${NAV_FILES[i]}"
		cur_nav_dir="$(dirname "$cur_nav")"
		volume_num=$((i + 1))

		ref="$cur_nav_dir/$(get_xml_attr "a[[:space:]]*href" "href" "$cur_nav")"
		if [[ -n "${TOC_VOLUME_LABELS[i]:-}" ]]; then
			local label="${TOC_VOLUME_LABELS[i]}"
		else
			local label="$prefix$volume_num$suffix"
		fi

		# Add volume entry and link
		echo "<li style='list-style: none !important; margin: 0 !important; padding: 0 !important;' id=\"vol-$i=\"><a href=\"$ref\">$(escape_xml "$label")</a></li>"

		# Merge navigation points
		debug_var cur_nav_dir
		extract_and_modify_xml \
			nav "epub.type=.toc." "$cur_nav_dir" "$i" "$cur_nav" \
			| grep -v '<h[0-6]'
	done >> "$nav_file"

	# Close NAV structure
	echo -e '</ol></nav>\n</body>\n</html>' >> "$nav_file"
	sed_i -E "
	$SED_REMOVE_DOT_PATH
	$SED_REMOVE_DOTDOT_PATH
	" "$nav_file" "$nav_file"
	format_xml "$nav_file"
}

# Merge all OPF manifests and spines
merge_opfs() {
	debug_func "$@"
	local uuid="$1"
	local manifest_file="content.opf.manifest"
	local spine_file="content.opf.spine"

	# Initialize OPF with header
	gen_opf_header "${OPF_FILES[0]}" "$EPUB_TITLE" \
		| sed "s/$UUID_PATTERN/$uuid/" \
		> "content.opf"

	# Process each volume for manifest and spine
	for i in "${!EPUB_FILES[@]}"; do
		cur_opf="${OPF_FILES[i]}"
		cur_opf_dir="$(dirname "$cur_opf")"

		# Extract and modify spine entries
		extract_and_modify_xml \
				"spine" "" "$cur_opf_dir" "$i" "$cur_opf" \
			>> "$spine_file"

		# Extract manifest entries with unique IDs and corrected paths.
		extract_and_modify_xml \
				"manifest" "" "$cur_opf_dir" "$i" "$cur_opf" \
			>> "$manifest_file"
	done

	if [[ ! -s "$manifest_file" && ! -s "$spine_file" ]]; then
		error "Failed to read <spine> or <manifest> in OPF file"
	fi

	# Assemble final OPF
	{
		echo "  <manifest>"
		if [[ -n "$FIRST_NAV" ]]; then
			# Add only one nav property
			echo "<item id=\"$MERGED_NAV_ID\" href=\"$MERGED_NAV_FILE\" media-type=\"application/xhtml+xml\" properties=\"nav\"/>"
		fi

		# Remove all nav properties
		sed "s:[[:space:]]*properties[[:space:]]*=[[:space:]]*[\"']nav[^\"']*[\"']::" "$manifest_file"

		echo "  </manifest>"

		if [[ -n "$FIRST_NCX" ]]; then
			echo "<spine toc=\"$MERGED_NCX_ID\">"
		else
			echo "<spine>"
		fi

		cat "$spine_file"
		echo -e "  </spine>\n</package>"
	} \
	| sed -E "
	s:\"0/[^\"']*\.ncx\":\"$MERGED_NCX_FILE\":
	s:\"${FIRST_NCX_ID}-0\":\"$MERGED_NCX_ID\":
	s:\"${FIRST_NCX_ID}\":\"$MERGED_NCX_ID\":
	$SED_REMOVE_DOTDOT_PATH
	$SED_REMOVE_DOT_PATH
	" \
	| fix_font_paths \
	| filter_dups \
	| grep -ivE '[0-9][0-9]*/.*\.(ncx|otf|ttf|woff|woff2|eot)' \
	>> "content.opf"

	to_nfc content.opf
	format_xml content.opf

	rm -f "$manifest_file" "$spine_file"
}

# Backup original files for splitting
backup_originals() {
	debug_func
	mkdir -p .epub-merge

	local no_ncx="___no_ncx_file___"
	local no_nav="___no_nav_file___"

	adjust_path() {
		local path="$1" idx="$2"
		echo "${path}/" | sed -E "s:^$idx/::; s://:/:; s:^$:.:"
	}

	for i in "${!EPUB_FILES[@]}"; do
		local cur_opf="${OPF_FILES[i]}"
		local cur_ncx="${NCX_FILES[i]:-$no_ncx}"
		local cur_nav="${NAV_FILES[i]:-$no_nav}"

		local new_opf_dir new_ncx_dir new_nav_dir
		new_opf_dir=$(adjust_path "$(dirname "$cur_opf")" "$i")
		new_ncx_dir=$(adjust_path "$(dirname "$cur_ncx")" "$i")
		new_nav_dir=$(adjust_path "$(dirname "$cur_nav")" "$i")

		local cur_ncx_id
		if [[ "$cur_ncx" != "$no_ncx" ]]; then
			cur_ncx_id=$(grep "$(basename "$cur_ncx")" "$cur_opf" \
				| sed -n -E 's/.*id="([^"]*)".*/\1/p')
		fi
		cur_ncx_id="${cur_ncx_id:-$no_ncx}"

		# OPF
		format_xml "$cur_opf"
		sed -E "
		s:<(item|reference).*href=[\"']:&$new_opf_dir/:g
		s:(<(item|reference).*href=.*)(//):\1/:
		$SED_REMOVE_DOT_PATH
		s:href=\"[^\"]*\.ncx\":href=\"toc.ncx\":
		s:href=\"[^\"]*$(basename "$cur_nav")\":href=\"$MERGED_NAV_FILE\":
		s:[\"']${cur_ncx_id}[\"']:\"ncx\":" "$cur_opf" \
		| fix_font_paths \
		> ".epub-merge/$i.opf"

		# NCX
		if [[ "$cur_ncx" != "$no_ncx" ]]; then
			format_xml "$cur_ncx"
			sed -E "
			s:src=\":&$new_ncx_dir/:g
			s:(src=.*)(//):\1/:
			s:src=\"[^\"]*$(basename "$cur_nav")\":href=\"$MERGED_NAV_FILE\":
			$SED_REMOVE_DOT_PATH" "$cur_ncx" \
			> ".epub-merge/$i.ncx"
		fi

		# NAV
		if [[ "$cur_nav" != "$no_nav" ]]; then
			format_xml "$cur_nav"
			sed -E "
			s:(href=\")([^#]):\1$new_nav_dir/\2:g
			s:(href=.*)(//):\1/:
			s:href=\"[^\"]*$(basename "$cur_nav")\":href=\"$MERGED_NAV_FILE\":
			$SED_REMOVE_DOT_PATH
			$SED_REMOVE_DOTDOT_PATH" "$cur_nav" \
			> ".epub-merge/$i.nav"
		fi

		# Filename
		basename "${EPUB_FILES[i]}" > ".epub-merge/$i.name"
		to_nfc ".epub-merge/$i.name"
	done
}

# Consolidate merged archive, and remove unused consolidate_merged() {
consolidate_merged() {
	debug_func "*@"
	# Move all font files to central location
	mkdir fonts
	find [0-9]* -type f \( \
		-iname "*.ttf" -o -iname "*.otf" -o -iname "*.woff*" -o -iname "*.eot"  \) \
		-exec mv {} fonts/ \; 2>/dev/null || true
	rmdir fonts 2>/dev/null || true

	# Remove unused
	find [0-9]* \( -iname "META-INF" -o -iname "mimetype" \
		-o -iname "*.opf" -o -iname "*.ncx" \) \
		-exec rm -rf {} + 2>/dev/null || true

	find [0-9]* -type d -empty -delete || true
}

# Calculate relative path to root
path_to_root() {
	local parent
	parent="$(dirname "$1" | sed 's:^\./::')"

	if [ "$parent" = "." ]; then
		echo "."
	else
		# shellcheck disable=SC2001
		echo "$parent" | sed 's#[^/][^/]*#..#g'
	fi
}

# Update CSS font URLs for merged ePUB
# Merged, so one depth more
fix_fontpaths_to_root() {
	local rpath
	rpath="$(path_to_root "$1")"
	sed_i -E "s#url[[:space:]]*\([^)]*/([^/]+\.(ttf|otf|woff|woff2|eot))[^)]*\)#url(${rpath}/fonts/\\1)#i" "$1"
}

# Calculate relative path to trunk (one level below root)
path_to_trunk() {
	local parent
	parent="$(dirname "$(dirname "$1" | sed -e 's:^\./::')")"

	if [ "$parent" = "." ]; then
		echo ""
	else
		echo "$parent/" | sed 's#[^/][^/]*#..#g'
	fi
}

# Update CSS font URLs for split ePUBs
# Trunk dirs(0, 1, 2, ...) are now root
fix_fontpaths_to_trunk() {
	local rpath
	rpath="$(path_to_trunk "$1")"
	sed_i -E "s#url[[:space:]]*\([^)]*/([^/]+\.(ttf|otf|woff|woff2|eot))[^)]*\)#url(${rpath}fonts/\\1)#i" "$1"
}

# Update CSS font URLs for split ePUB (digits/path -> ../fonts/)
update_css_fonts_for_split() {
	debug_func "*@"
	find . -type f -iname "*.css" -print0 | while IFS= read -r -d '' css; do
		fix_fontpaths_to_trunk "$css"
	done
}

# Update CSS font URLs for merged ePUB (paths -> fonts/)
update_css_fonts_for_merge() {
	debug_func "*@"
	find . -type f -iname "*.css" -print0 | while IFS= read -r -d '' css; do
		# New path from css to font is the concatenation of path from 
		# css to altered root and altered font path (/fonts)
		fix_fontpaths_to_root "$css"
	done
}

# Create final ePUB file
create_final_epub() {
	debug_func "$@"
	local output_realpath="$1"
	local working_dir="$2"
	local fonts_parent_dir="${3:-}"

	# Package ePUB with proper compression
	cd "$working_dir" > /dev/null
	rm -f "$TEMP_EPUB"
	zip -q -X0 "$TEMP_EPUB" mimetype
	zip -q -Xr9D "$TEMP_EPUB" . -x mimetype -x "*/.DS_Store" -x "__MACOSX/*"

	if [[ -n "$fonts_parent_dir" ]]; then
		debug_var fonts_parent_dir
		cd - > /dev/null
		cd "$fonts_parent_dir/" > /dev/null
		if [[ -d "$fonts_parent_dir/fonts" ]]; then
			zip -q -r "$TEMP_EPUB" "fonts/"
		fi
		cd - > /dev/null
	fi

	cd - > /dev/null
	if mv -f "$TEMP_EPUB" "$output_realpath"; then
		log "$(basename "$output_realpath"): successfully created"
		return 0
	else
		log "$(basename "$output_realpath"): failed to create"
		return 1
	fi
}

# Create individual ePUB files from extracted merged ePUB
create_individual_epubs() {
	local status=0
	local count
	local toc_file="toc.ncx"
	local nav_file="nav.xhtml"

	find fonts -type f | sort -V | sed 's#^..##' > .all-fonts-list 2>/dev/null || true

	# shellcheck disable=SC2012
	count="$(ls .epub-merge/[0-9]*.opf 2>/dev/null | wc -l)"

	local i
	for i in $(seq 0 $((count - 1))); do
		local cur_epub
		cur_epub="$(cat ".epub-merge/$i.name")"

		if [[ $OVERWRITE_EXISTING != 1 && \
			-f "$OUTPUT_DIR/$cur_epub" ]]; then
			status=1
			orange_log "$cur_epub: already exists"
			continue
		fi

		cp -r META-INF mimetype "$i"/
		cp .epub-merge/"$i".opf "$i"/content.opf
		[[ -f .epub-merge/"$i".ncx ]] && cp .epub-merge/"$i".ncx "$i/$toc_file"
		[[ -f .epub-merge/"$i".nav ]] && cp .epub-merge/"$i".nav "$i/$nav_file"

		sed -n 's/.*href="\(fonts\/[^"]*\)".*/\1/p' "$i"/content.opf \
			| sort -V > .fonts-list || true

		local different_fonts=""

		if ! diff .fonts-list .all-fonts-list >/dev/null 2>&1; then
			different_fonts=1
		fi

		if [[ $different_fonts == 1 ]]; then
			mkdir "$i/fonts"
			sed "s#.*#cp \"&\" $i/fonts/#" .fonts-list | bash - 
			if ! create_final_epub "$OUTPUT_DIR/$cur_epub" "$i/"; then
				status=1
			fi
			rmdir fonts 2>/dev/null || true
		else
			if ! create_final_epub "$OUTPUT_DIR/$cur_epub" "$i/" "."; then
				status=1
			fi
		fi

		cd "$TEMP_DIR" > /dev/null
	done

	return $status
}

# Extract merged ePUB and split into original files
extract_merged_epub() {
	debug_func "$@"
	if ! validate_epub "$1" 1; then
		error "Program exits in extract_merged_epub"
	fi

	# `mktemp` should be done before extracting args
	TEMP_DIR="$(mktemp -d)"

	unzip -q "$1" -d "$TEMP_DIR"

	# `cd` should be done after extracting args
	cd "$TEMP_DIR" > /dev/null

	# Update font paths in all CSS files to point to centralized fonts 
	update_css_fonts_for_split

	create_individual_epubs
}

# Verify all ePUB files have same version
check_epub_versions() {
	debug_func "$@"
	local first_version
	first_version="$(get_version "$1")"

	if [[ -z "$first_version" || \
			( "$first_version" != "2.0" && \
                  "$first_version" != "3.0" ) ]]; then
		error "Failed to get ePUB version ($1)"
	fi

	if [[ -z "$first_version" \
			|| ( "$first_version" != "2.0" 
				&& "$first_version" != "3.0" ) ]]; then
		error "Failed to get ePUB version ($1)"
	fi

	local files=("$@")
	if (( ${#files[@]} <= 1 )); then
		echo "$first_version"
		return 0
	fi

	local remaining_files=("${files[@]:1}")

	for epub in "${remaining_files[@]}"; do
		epub_version="$(get_version "$epub")"
		if [[ "$epub_version" != "$first_version" ]]; then
			ver="$1 -> '$first_version', $epub -> '$epub_version'"
			error "Different ePUB versions ($ver)"
		fi
	done

	echo "$first_version"
}

main() {
	parse_args "$@"
	shift $((OPTIND-1))

	# Check if unzip, zip, and uuidgen installed
	check_deps || error "Program exits"

	# Validate command line arguments
	validate_args "$@"

	# Check ePUBs versions
	EPUB_VERSION="$(check_epub_versions "$@")"
	readonly EPUB_VERSION

	debug_var EPUB_VERSION
	TEMP_EPUB="$(mktemp "${OUTPUT_DIR}/.epub-merge.XXXXX")"
	readonly TEMP_EPUB

	if [[ -n "$EXTRACT_MODE" ]]; then
		extract_merged_epub "$1" && exit 0 || exit 1
	fi

	# Determine output filename and epub title
	gen_output_names "$1" "$2"

	# Validate all ePUB files
	for epub in "$@"; do
		validate_epub "$epub" 0
	done

	# Sort input files and save them to EPUB_FILES
	sort_files "$@"

	# Create temporary directory
	TEMP_DIR="$(mktemp -d)"

	# Extract all ePUBs to 0/, 1/, 2/, ... in temp_dir
	extract_files

	# Now, we move to working directory
	cd "$TEMP_DIR" > /dev/null

	# Get paths lists OPF/NCX/NAV_FILES
	collect_file_paths_and_format_xml

	# Setup base structure (mimetype, META-INF/*, ...)
	setup_base

	# Detect language
	EPUB_LANG="$(detect_language "${OPF_FILES[0]}" "$EPUB_LANG")"
	readonly EPUB_LANG
	detect_volume_labels

	local uuid
	uuid="$(uuidgen)"

	# Generate NCX/NAV/OPF
	merge_navs
	merge_ncxs "$uuid"
	merge_opfs "$uuid"

	# Backup [0-9]*/**/*.(opf|ncx|nav) to ".epub-merged/"
	backup_originals

	# Consolidate merged archive and remove unused
	consolidate_merged

	# Update CSS font references
	update_css_fonts_for_merge

	create_final_epub "$OUTPUT_DIR/$EPUB_NAME.epub" "."
}

# Run main function with all arguments
if [ -z "${EPUB_MERGE_TEST:-}" ]; then
	main "$@"
fi
